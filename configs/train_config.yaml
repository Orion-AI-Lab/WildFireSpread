dataset:
  train_dataset:    'WildFireSpread/train_dataset'                   # path to dataset contaaining train and validation samples
  checkpoints:      'WildFireSpread/WildFireSpread_UNET/checkpoints' # path to save model checkpoints after each epoch

model:
  num_filters:      [64] # number of filters in encoder and decoder blocks ( [64, 128, 512] or [32, 64, 128] pr [64, 128] ) 128 256 or 64 128 [16, 32, 64]
  kernel_size:      3             # kernel size (filter size) 3x3, 5x5, 7x7
  pool_size:        (1, 2, 2)      # feature map size (1, 2, 2)
  use_batchnorm:    True           # normalize after convolution block with ReLU
  final_activation: null           # apply activation function in output (nn.Sigmoid), leave null and use in activation in test.py

training: 
  number_of_epochs: 200           # number of epochs
  batch_size:       3             # how many samples will be procesed in one run (not more than 10, it will run out of memory)
  learing_rate:     1e-4          # lerning rate
