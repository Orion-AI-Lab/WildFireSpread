model:
  num_filters:      '[64, 128, 256]'                                           # number of filters in encoder and decoder blocks ( [64, 128, 512] or [32, 64, 128] pr [64, 128] ) 128 256 or 64 128 [16, 32, 64]
  kernel_size:      '(5, 3, 3)'                                       # kernel size (filter size) 3x3x3, 5x3x3, 5x5x5, should be time, height, width
  pool_size:        '(1, 1, 1)'                                       # feature map size (1, 2, 2)
  use_batchnorm:    'True'                                            # normalize after convolution block with ReLU
  final_activation: 'None'                                            # apply activation function in output (nn.Sigmoid), leave null and use in activation in test.py
  checkpoints:      'WildFireSpread/WildFireSpread_UNET/checkpoints'  # path to save model checkpoints after each epoch

training: 
  number_of_epochs: '200'           # number of epochs
  batch_size:       '8'             # how many samples will be procesed in one run (not more than 10, it will run out of memory)
  learing_rate:     '1e-3'          # lerning rate
  drop_out_rate:    '0.5'           # drop out rate
